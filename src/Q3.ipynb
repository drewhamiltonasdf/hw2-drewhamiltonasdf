{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.activate(joinpath(@__DIR__,\"..\")); Pkg.instantiate()\n",
    "using LinearAlgebra\n",
    "using SparseArrays\n",
    "using ForwardDiff\n",
    "using OSQP\n",
    "using RobotDynamics\n",
    "using RobotZoo: PlanarRocket\n",
    "using RobotZoo\n",
    "using StaticArrays\n",
    "using Plots\n",
    "using JLD2\n",
    "using Test\n",
    "using Statistics\n",
    "using ControlSystems\n",
    "const resfile = joinpath(@__DIR__, \"Q3.jld2\")\n",
    "include(\"rocket.jl\")\n",
    "const isautograder = @isdefined autograder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Writing an MPC Controller (50 pts)\n",
    "In this problem we'll compare the performance of LQR with a QP-based MPC controller for landing a rocket booster. \n",
    "\n",
    "## The Dynamics\n",
    "We'll be solving a simplified version of the rocket soft landing problem. We'll only be considering a planar version where we control the lateral and vertical movement of the rocket by rotating the thrust vector. The dynamics are as follows:\n",
    "\n",
    "$$ \n",
    "x = \\begin{bmatrix} p_x \\\\ p_z \\\\ \\theta \\\\ v_x \\\\ v_z \\\\ \\omega \\\\ T \\\\ \\phi \\end{bmatrix}, \\quad\n",
    "u = \\begin{bmatrix} \\dot{T} \\\\ \\dot{\\phi} \\end{bmatrix}, \\quad\n",
    "\\dot{x} = \\begin{bmatrix}\n",
    "v_z \\\\ v_z \\\\ \\omega \\\\\n",
    "\\frac{T}{m} \\cos{(\\theta + \\phi)} \\\\ \n",
    "\\frac{T}{m} \\sin{(\\theta + \\phi)} \\\\\n",
    "\\frac{T}{2J} L \\sin(\\phi) \\\\\n",
    "\\dot{T} \\\\ \\dot{\\phi}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "where $p_x$ is the lateral displacement, $p_z$ is the altitude, $\\theta$ is the roll angle, $v_x$ and $v_z$ are the linear velocities, $\\omega$ is the roll rate, $T$ is the total thrust, $\\phi$ is the thrust angle, $\\dot{T}$ and $\\dot{\\phi}$ are the thrust and thrust angle rates, $m$ is the mass, $J$ is the moment of inertia, $L$ is the distance from the thruster to the center of mass, and $g$ is gravity.\n",
    "\n",
    "To keep our solution stable and safe, we'll saturate our thrust to be between 75%-150% of the nominal gravity-compensating thrust, our thrust angle with $\\pm$10 degrees, and our roll angle between $\\pm$5 degrees.\n",
    "\n",
    "Again, we've already defined a `RobotDynamics` model that implements these dynamics for you, but it's helpful to understand the dynamics model you're working with.\n",
    "\n",
    "**NOTE**: We're using RobotDynamics v0.3.4. A newer version exists with a refreshed API, but we'll stick with this version since it's a little simpler.\n",
    "\n",
    "## Our Goal\n",
    "During this problem we will generate an LQR controller, an unconstrained MPC controller, and a constrained MPC controller. We will use each of these controllers to solve a simplified version of the \"rocket soft landing problem.\" The final output using the constrained MPC solver should look something like this:\n",
    "![rocket](../rocket.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: While using global variables is typically discouraged in Julia, feel free to use\n",
    "#       any of the variables marked \"const\" within your methods.\n",
    "\n",
    "# Planar Rocket model\n",
    "model = PlanarRocket(max_roll=5.0)\n",
    "const n = state_dim(model)\n",
    "const m = control_dim(model)\n",
    "const xeq = [zeros(6); model.m*model.g; 0]\n",
    "const ueq = zeros(2) \n",
    "norm(dynamics(model, xeq, ueq)) ≈ 0 # make sure it's an equilibrium point\n",
    "const dt = 0.1  # time step (s)\n",
    "const tf = 25   # time horizon (s)\n",
    "const N = Int(tf / dt) + 1\n",
    "\n",
    "# Evaluate the continuous and discrete Jacobians\n",
    "zeq = KnotPoint(xeq,ueq,dt)   # create a `KnotPoint` type that stores everything together\n",
    "∇f = RobotDynamics.DynamicsJacobian(model)\n",
    "jacobian!(∇f, model, zeq)\n",
    "discrete_jacobian!(RK4, ∇f, model, zeq)\n",
    "\n",
    "# Extract pieces of the Jacobian\n",
    "const A = ∇f.A\n",
    "const B = ∇f.B;\n",
    "\n",
    "# Cost matrices (using Bryson's Rule)\n",
    "const Q = Diagonal([\n",
    "    1.0/5^2; \n",
    "    1.0/5^2; \n",
    "    1.0/(10*pi/180)^2; \n",
    "    10.0/5^2; \n",
    "    10.0/5^2; \n",
    "    10.0/(10*pi/180)^2;\n",
    "    1/(.1*model.m*model.g)^2; \n",
    "    1/(10*pi/180)^2\n",
    "])\n",
    "const R = Diagonal([\n",
    "    1/(20*model.m*model.g)^2,\n",
    "    1/(deg2rad(10))^2\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (a): Design a reference trajectory (3 pts)\n",
    "As we saw in previous problem, we'll need a reference trajectory for our controller. However, in this case our reference trajectory is a very simple trajectory that provides a reasonable guess but we expect the actual solution to be different. We'll later see how this reference trajectory affects the performance of our controller.\n",
    "\n",
    "For the rocket problem, we'll be starting at an altitude of 500m and 200m to the West of our landing location. We'll use a simple linear interpolation from our expected initial state and our goal location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: implement this method (3 pts)\n",
    "\"\"\"\n",
    "    nominal_trajectory(x0, N, dt)\n",
    "\n",
    "Generate the nominal trajectory for the rocket problem, given the initial state `x0`,\n",
    "horizon length `N`, and time step `dt`. \n",
    "\n",
    "The guess should be a linear interpolation of the positions.\n",
    "The velocities should should be consistent with the positions (i.e. constant).\n",
    "The last state should be have position and velocity of 0, but the same nominal\n",
    "actuator commands as initial state (i.e. T and ϕ should be constant)\n",
    "\n",
    "**TIP**: Use a simple finite difference to calculate the velocities.\n",
    "\"\"\"\n",
    "function nominal_trajectory(x0,N,dt)\n",
    "    Xref = [fill(NaN, length(x0)) for k = 1:N]\n",
    "    \n",
    "    # TODO: Design a trajectory that linearly interpolates from x0 to the origin\n",
    "    \n",
    "    return SVector{8}.(Xref)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start 500m off the ground and 200m West\n",
    "x0_ref = [-200, 500, 0, 0, 0, 0, 0, 0.] + xeq\n",
    "\n",
    "# Generate reference trajectory\n",
    "Xref = nominal_trajectory(x0_ref,N,dt)\n",
    "Uref = [copy(ueq) for k = 1:N]\n",
    "tref = range(0,tf, length=N)\n",
    "\n",
    "# Plot the trajectory\n",
    "isautograder || traj2(Xref, xlabel=\"x (m)\", ylabel=\"altitude (m)\", label=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"Q3a\" begin                                      # POINTS = 3\n",
    "    xdiff = diff(Xref)[1:end-1]\n",
    "    @test mean(xdiff)[1] ≈ 200 / (N-1) rtol = 1e-6        # POINTS = 0.5\n",
    "    @test mean(xdiff)[2] ≈ -500 / (N-1) rtol = 1e-6       # POINTS = 0.5\n",
    "    @test mean(xdiff)[3:end] ≈ zeros(6) rtol = 1e-6       # POINTS = 0.5\n",
    "    \n",
    "    Xref2 = nominal_trajectory([100,200,0, 0,0,0, 12.2, 0.], 101, 0.15)\n",
    "    xmean = mean(Xref2[1:end-1])\n",
    "    @test xmean[4] ≈ -100 / 100 / .15 rtol = 1e-6         # POINTS = 0.5\n",
    "    @test xmean[5] ≈ -200 / 100 / .15 rtol = 1e-6         # POINTS = 0.5\n",
    "    @test xmean[6] ≈ 0                                    # POINTS = 0.2\n",
    "    @test xmean[7] ≈ 12.2                                 # POINTS = 0.2\n",
    "    @test xmean[8] ≈ 0                                    # POINTS = 0.1\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b): Design an LQR Controller (5 pts)\n",
    "As we saw in Q1, a simple infinite-gain LQR controller can work extremely effectively. Write a method to calculate the infinite-horizon gain `K` and cost-to-go `P`. We'll use `K` to control our system and `P` as the $Q_f$ weight matrix for our MPC controller later. It's fine to solve the LQR problem with a long horizon until the cost-to-go converges to a steady-state value. You should NOT use `dlqr` or `dare` from the ControlSystems package, but you can use those methods to check your answer. \n",
    "\n",
    "The controller stores a reference trajectory, which is tracked online using the same `K` matrix. This is valid since our dynamics linearization is invariant to the spatial location of the rocket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Implement the following methods:\n",
    "#       get_control (3 pts)\n",
    "#       lqr         (2 pts)\n",
    "\n",
    "\"\"\"\n",
    "    LQRController\n",
    "\n",
    "Type for evaluting an infinite-horizon time-invariant LQR control policy. \n",
    "\"\"\"\n",
    "struct LQRController\n",
    "    K::Matrix{Float64}\n",
    "    Xref::Vector{Vector{Float64}}\n",
    "    Uref::Vector{Vector{Float64}}\n",
    "    times::Vector{Float64}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    get_k(ctrl, t)\n",
    "\n",
    "Get the time index corresponding to time `t`. \n",
    "Useful for implementing zero-order hold control.\n",
    "Uses binary search to find the time index.\n",
    "\"\"\"\n",
    "get_k(controller, t) = searchsortedlast(controller.times, t)\n",
    "\n",
    "\"\"\"\n",
    "    get_control(ctrl, x, t)\n",
    "\n",
    "Evaluate the LQR feedback policy at state `x` and time `t`, returning the control \n",
    "to be executed by the system.\n",
    "\"\"\"\n",
    "function get_control(ctrl::LQRController, x, t)\n",
    "    k = get_k(ctrl, t)\n",
    "    # TODO: Implement the control policy\n",
    "    u = fill(NaN, length(ctrl.Uref[1]))\n",
    "    return u\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    lqr(A,B,Q,R; kwargs...)\n",
    "\n",
    "Calculate the infinite-horizon LQR gain from dynamics Jacobians `A` and `B` and\n",
    "cost matrices `Q` and `R`. Returns the infinite-horizon gain `K` and cost-to-go `P`.\n",
    "\n",
    "# Keyword Arguments\n",
    "* `P`: Provide an initial guess for the infinite-horizon gain\n",
    "* `max_iters`: maximum number of iterations\n",
    "* `tol`: tolerance for solve\n",
    "` `verbose`: print the number of iterations\n",
    "\"\"\"\n",
    "function lqr(A,B,Q,R; P=Matrix(Q), tol=1e-8, max_iters=400, verbose=false)\n",
    "    # initialize the output\n",
    "    n,m = size(B)\n",
    "    K = zeros(m,n)\n",
    "    \n",
    "    # TODO: calculate the infinite-horizon LQR solution\n",
    "    \n",
    "    # return the feedback gains and ctg matrices\n",
    "    return K,P\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LQR controller\n",
    "K,Qf = lqr(A,B,Q,R)\n",
    "ctrl = LQRController(K,Xref,Uref,tref);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate and visualize the result\n",
    "if !isautograder\n",
    "    vis = initialize_visualizer(model)\n",
    "    render(vis)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = zeros(8)\n",
    "dx[1:2] .= [10,10]  # we're off from our initial spot by a few meters\n",
    "dx[5] = -10         # it's coming down a little faster than expected\n",
    "dx[6] = 1.1         # add some initial angular velocity\n",
    "x0 = Xref[1] + dx\n",
    "Xlqr,Ulqr,tlqr = simulate(model, x0, ctrl, tf=50)\n",
    "isautograder || visualize!(vis, model, tlqr[end] / 10, Xlqr)  # divide the time to speed it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"Q3b\" begin                          # POINTS = 5\n",
    "    dx = [\n",
    "        1.929094900384797,\n",
    "        1.3289659218797703,\n",
    "       -1.1940032610827314,\n",
    "        0.6035052846069947,\n",
    "        0.1223347579198458,\n",
    "       -1.0399155799859232,\n",
    "        0.2632145814885595,\n",
    "       -1.0004103548732461\n",
    "    ]\n",
    "    @test ctrl.K ≈ dlqr(A,B,Matrix(Q),Matrix(R)) rtol = 1e-3   # POINTS = 0.5\n",
    "    @test Qf ≈ dare(A,B,Matrix(Q),Matrix(R)) rtol = 1e-3       # POINTS = 0.5\n",
    "    xtest = xeq + dx\n",
    "    @test all(1:N-1) do k\n",
    "        get_control(ctrl, Xref[k], tref[k]) ≈ zeros(2)\n",
    "    end\n",
    "    @test !(get_control(ctrl, xtest, tref[1]) ≈ get_control(ctrl, xtest, tref[end]))  # POINTS = 0.5\n",
    "    @test get_control(ctrl, Xref[10] + xtest, tref[10]) ≈ \n",
    "        get_control(ctrl, Xref[end] + xtest, tref[end])                               # POINTS = 0.5   \n",
    "\n",
    "    @test norm(Xlqr[end][4:6]) < 0.1                                                  # POINTS = 1\n",
    "    @test norm(Xlqr[end][1:3]) < 0.1                                                  # POINTS = 1\n",
    "    @test minimum([x[2] for x in Xlqr]) < -10\n",
    "    @test maximum([x[7] for x in Xlqr]) > RobotZoo.umax(model)[1]                     # POINTS = 0.5\n",
    "    @test maximum([abs(x[3]) for x in Xlqr]) > deg2rad(model.max_roll)                # POINTS = 0.5\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c): Design an MPC Controller (30 pts)\n",
    "We'll now design QP-based MPC controller for our rocket. We've set up the basic structure below, which is already setup to work with OSQP. Your job is to generate the QP OSQP will need to solve at each iteration.\n",
    "\n",
    "Your QP should look something like this:\n",
    "$$ \\begin{align}\n",
    "    &\\text{minimize}_{z} && \\frac{1}{2} z^T P z + q^T z \\\\\n",
    "    &\\text{subject to} && D z = d \\\\\n",
    "    &&& C z \\leq d \\\\\n",
    "\\end{align} $$\n",
    "\n",
    "where $z$ is the concatenated vector of states and controls at each time step. Since we've linearized our system about the point $(x_\\text{eq}, u_\\text{eq})$, these state and controls are defined relative to this reference. The equality constraints are just the linearized dynamics constraints:\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} \n",
    "    B & -I \\\\ \n",
    "      & A & B & -I \\\\\n",
    "      &   &   &   & \\ddots \\\\\n",
    "      &   &   &   & & A & B -I \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} u_0 \\\\ x_1 \\\\ u_1 \\\\ \\vdots \\\\ x_{N-1} \\\\ u_{N-1} \\\\ x_N \\end{bmatrix} = \n",
    "\\begin{bmatrix} -A (x_1 - x_{eq}) \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and the cost matrices $P$ and $q$ look are defined as:\n",
    "$$\n",
    "P = \\begin{bmatrix}\n",
    "R \\\\\n",
    "& Q \\\\\n",
    "&& \\ddots \\\\\n",
    "&&& R \\\\\n",
    "&&&& Q_f\n",
    "\\end{bmatrix}, \\quad\n",
    "q = \\begin{bmatrix}\n",
    "    -R(\\bar{u}_1 - u_{eq}) \\\\\n",
    "    -Q(\\bar{x}_2 - x_{eq}) \\\\\n",
    "    \\vdots \\\\\n",
    "    -R(\\bar{u}_{N-1} - u_{eq}) \\\\\n",
    "    -Q_f(\\bar{x}_N - x_{eq}) \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Note that the states and controls in our QP are defined relative to our linearization point at the origin $(x_{eq}, u_{eq})$. As the MPC progresses along the horizon, the reference states and controls $(\\bar{x},\\bar{u})$ will change.\n",
    "\n",
    "We won't have inequality constraints in this part, but we'll add them in the next section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the code in this cell is provided. There is no need to modify it.\n",
    "\"\"\"\n",
    "    MPCController\n",
    "\n",
    "An MPC controller that uses a solver of type `S` to solve a QP at every iteration.\n",
    "\n",
    "It will track the reference trajectory specified by `Xref`, `Uref` and `times` \n",
    "with an MPC horizon of `Nmpc`. It will track the terminal reference state if \n",
    "the horizon extends beyond the reference horizon.\n",
    "\"\"\"\n",
    "struct MPCController{S}\n",
    "    P::SparseMatrixCSC{Float64,Int}\n",
    "    q::Vector{Float64}\n",
    "    A::SparseMatrixCSC{Float64,Int}\n",
    "    lb::Vector{Float64}\n",
    "    ub::Vector{Float64}\n",
    "    Nmpc::Int\n",
    "    solver::S\n",
    "    Xref::Vector{Vector{Float64}}\n",
    "    Uref::Vector{Vector{Float64}}\n",
    "    times::Vector{Float64}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    OSQPController(n,m,N,Nref,Nd)\n",
    "\n",
    "Generate an `MPCController` that uses OSQP to solve the QP.\n",
    "Initializes the controller with matrices consistent with `n` states,\n",
    "`m` controls, and an MPC horizon of `N`, and `Nd` constraints. \n",
    "\n",
    "Use `Nref` to initialize a reference trajectory whose length may differ from the \n",
    "horizon length.\n",
    "\"\"\"\n",
    "function OSQPController(n::Integer, m::Integer, N::Integer, Nref::Integer=N, Nd::Integer=(N-1)*n)\n",
    "    Np = (N-1)*(n+m)   # number of primals\n",
    "    P = spzeros(Np,Np)\n",
    "    q = zeros(Np)\n",
    "    A = spzeros(Nd,Np)\n",
    "    lb = zeros(Nd)\n",
    "    ub = zeros(Nd)\n",
    "    Xref = [zeros(n) for k = 1:Nref]\n",
    "    Uref = [zeros(m) for k = 1:Nref]\n",
    "    tref = zeros(Nref)\n",
    "    solver = OSQP.Model()\n",
    "    MPCController{OSQP.Model}(P,q, A,lb,ub, N, solver, Xref, Uref, tref)\n",
    "end\n",
    "\n",
    "isconstrained(ctrl::MPCController) = length(ctrl.lb) != (ctrl.Nmpc - 1) * length(ctrl.Xref[1])\n",
    "\n",
    "\"\"\"\n",
    "    buildQP!(ctrl, A,B,Q,R,Qf; kwargs...)\n",
    "\n",
    "Build the QP matrices `P` and `A` for the MPC problem. Note that these matrices\n",
    "should be constant between MPC iterations.\n",
    "\n",
    "Any keyword arguments will be passed to `initialize_solver!`.\n",
    "\"\"\"\n",
    "function buildQP!(ctrl::MPCController, A,B,Q,R,Qf; kwargs...)\n",
    "    if isconstrained(ctrl)\n",
    "        buildQP_constrained!(ctrl::MPCController, A,B,Q,R,Qf; kwargs...)\n",
    "    else\n",
    "        buildQP_unconstrained!(ctrl::MPCController, A,B,Q,R,Qf; kwargs...)\n",
    "    end\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    updateQP!(ctrl::MPCController, x, time)\n",
    "\n",
    "Update the vectors in the QP problem for the current state `x` and time `time`.\n",
    "This should update `ctrl.q`, `ctrl.lb`, and `ctrl.ub`.\n",
    "\"\"\"\n",
    "function updateQP!(ctrl::MPCController, x, time)\n",
    "    if isconstrained(ctrl)\n",
    "        updateQP_constrained!(ctrl, x, time)\n",
    "    else\n",
    "        updateQP_unconstrained!(ctrl, x, time)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    initialize_solver!(ctrl::MPCController; kwargs...)\n",
    "\n",
    "Initialize the internal solver once the QP matrices are initialized in the \n",
    "controller.\n",
    "\"\"\"\n",
    "function initialize_solver!(ctrl::MPCController{OSQP.Model}; tol=1e-6, verbose=false)\n",
    "    OSQP.setup!(ctrl.solver, P=ctrl.P, q=ctrl.q, A=ctrl.A, l=ctrl.lb, u=ctrl.ub, \n",
    "        verbose=verbose, eps_rel=tol, eps_abs=tol, polish=1)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    get_control(ctrl::MPCController, x, t)\n",
    "\n",
    "Get the control from the MPC solver by solving the QP. \n",
    "If you want to use your own QP solver, you'll need to change this\n",
    "method.\n",
    "\"\"\"\n",
    "function get_control(ctrl::MPCController{OSQP.Model}, x, time)\n",
    "    # Update the QP\n",
    "    updateQP!(ctrl, x, time)\n",
    "    OSQP.update!(ctrl.solver, q=ctrl.q, l=ctrl.lb, u=ctrl.ub)\n",
    "\n",
    "    # Solve QP\n",
    "    results = OSQP.solve!(ctrl.solver)\n",
    "    Δu = results.x[1:2]\n",
    "    \n",
    "    k = get_k(ctrl, time)\n",
    "    return ctrl.Uref[k] + Δu \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Implement the following methods:\n",
    "#       buildQP_unconstrained!  (15 pts)\n",
    "#       updateQP_unconstrained! (15 pts)\n",
    "function buildQP_unconstrained!(ctrl::MPCController, A,B,Q,R,Qf; kwargs...)\n",
    "     # TODO: Implement this method to build the QP matrices\n",
    "    \n",
    "    \n",
    "    # Initialize the included solver\n",
    "    #    If you want to use your QP solver, you should write your own\n",
    "    #    method for this function\n",
    "    initialize_solver!(ctrl; kwargs...)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "\n",
    "function updateQP_unconstrained!(ctrl::MPCController, x, time)\n",
    "    # TODO: Implement this method\n",
    "\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unconstrained MPC problem\n",
    "Nmpc = 51           # MPC Horizon\n",
    "mpc1 = OSQPController(n, m, Nmpc, length(Xref))\n",
    "\n",
    "# Provide the reference trajectory\n",
    "mpc1.Xref .= Xref\n",
    "mpc1.Uref .= Uref\n",
    "mpc1.times .= tref\n",
    "\n",
    "# Build the sparse QP matrices\n",
    "buildQP!(mpc1, A,B,Q,R,Qf, tol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isautograder || render(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmpc1,Umpc1,tmpc1 = simulate(model, x0, mpc1, tf=50)\n",
    "isautograder || visualize!(vis, model, tmpc1[end] / 10, Xmpc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Results\n",
    "Let's look at some plots to see how our LQR and MPC solutions compare.\n",
    "\n",
    "What do you see? How do the solutions differ? Can you see how the MPC controller is \"looking ahead?\" \n",
    "\n",
    "Your MPC results should be better than your simple LQR controller, but it will still be violating the constraints. Let's add some constraints to our QP to try to fix that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isautograder || comparison_plot(model, (Xlqr,Ulqr,tlqr,\"LQR\"), (Xmpc1,Umpc1,tmpc1,\"MPC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BlockArrays\n",
    "@testset \"Q3c\" begin                                   # POINTS = 30\n",
    "    Np = 50*(n+m)\n",
    "    Nd1 = 50*n\n",
    "    @test size(mpc1.P) == (Np,Np)                      # POINTS = 1\n",
    "    size(mpc1.A) == (Nd1, Np)\n",
    "    parts1 = fill(n,50)\n",
    "    parts2 = repeat([m,n],50)\n",
    "    D = PseudoBlockArray(mpc1.A, parts1, parts2)\n",
    "    @test D[Block(1,1)] ≈ B                            # POINTS = 1\n",
    "    @test D[Block(2,1)] ≈ zero(B)                      # POINTS = 1\n",
    "    @test D[Block(2,2)] ≈ A                            # POINTS = 1\n",
    "    @test D[Block(2,4)] ≈ -I(n)                        # POINTS = 1\n",
    "    @test D[Block(3,4)] ≈ A                            # POINTS = 1\n",
    "    @test D[Block(3,5)] ≈ B                            # POINTS = 1\n",
    "    @test D[Block(3,6)] ≈ -I(n)                        # POINTS = 1\n",
    "\n",
    "    H = PseudoBlockArray(mpc1.P, parts2, parts2)\n",
    "    @test H[Block(1,1)] ≈ R                            # POINTS = 1\n",
    "    @test H[Block(2,2)] ≈ Q                            # POINTS = 1\n",
    "    @test H[Block(100,100)] ≈ Qf                       # POINTS = 1\n",
    "    get_control(mpc1, Xref[1], tref[1])\n",
    "    g = PseudoBlockArray(mpc1.q, parts2)\n",
    "    @test g[Block(1)] ≈ zeros(2)                       # POINTS = 1\n",
    "    @test g[Block(2)] ≈ -Q*(Xref[2] - xeq)             # POINTS = 1\n",
    "    @test g[Block(3)] ≈ zeros(2)                       # POINTS = 1\n",
    "    @test g[Block(4)] ≈ -Q*(Xref[3] - xeq)             # POINTS = 1\n",
    "    @test g[Block(100)] ≈ -Qf*(Xref[51] - xeq)         # POINTS = 1\n",
    "\n",
    "    get_control(mpc1, Xref[1], tref[10])\n",
    "    @test g[Block(2)] ≈ -Q*(Xref[11] - xeq)            # POINTS = 1\n",
    "    @test g[Block(4)] ≈ -Q*(Xref[12] - xeq)            # POINTS = 1\n",
    "\n",
    "    get_control(mpc1, Xref[1], tref[end-10])\n",
    "    @test g[Block(2)] ≈ -Q*(Xref[242] - xeq)           # POINTS = 1\n",
    "    @test g[Block(2*9)] ≈ -Q*(Xref[250] - xeq)         # POINTS = 1\n",
    "    @test g[Block(2*11)] ≈ zeros(8)                    # POINTS = 1\n",
    "    @test mpc1.lb[1:n] ≈ -A*(Xref[1] - xeq)            # POINTS = 1\n",
    "\n",
    "    @test norm(Xmpc1[end][4:6]) < 1e-2                 # POINTS = 1\n",
    "    @test norm(Xmpc1[end][1:3]) < 1e-2                 # POINTS = 1\n",
    "    @test minimum([x[2] for x in Xmpc1]) < 0           # POINTS = 2\n",
    "    @test minimum([x[2] for x in Xmpc1]) > -5          # POINTS = 2\n",
    "    @test maximum([x[7] for x in Xmpc1]) - RobotZoo.umax(model)[1]  > 10        # POINTS = 1\n",
    "    @test maximum([abs(x[3]) for x in Xmpc1]) - deg2rad(model.max_roll) > 1e-2  # POINTS = 1\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (d): Add in Constraints (12 pts)\n",
    "Add the following constraints to your optimization problem:\n",
    "$$\\begin{align}\n",
    "    |\\theta | &\\leq 5^{\\circ} \\\\\n",
    "    |\\phi| & \\leq 10^{\\circ} \\\\\n",
    "    z &\\geq 0 \\\\\n",
    "    0.75 &\\leq \\frac{1}{mg} T \\leq 1.5\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**TASK**: Modify the `build_QP` and `update_QP` methods above to add in the  constraints . You should add some logic that checks only adds the constraints if there's room in the matrices, that way we can still use the method to generate our unconstrained solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    buildQP!(ctrl, A,B,Q,R,Qf; kwargs...)\n",
    "\n",
    "Build the QP matrices `P` and `A` for the MPC problem. Note that these matrices\n",
    "should be constant between MPC iterations.\n",
    "\n",
    "Any keyword arguments will be passed to `initialize_solver!`.\n",
    "\"\"\"\n",
    "function buildQP_constrained!(ctrl::MPCController, A,B,Q,R,Qf; kwargs...)\n",
    "    # TODO: Implement this method to build the QP matrices\n",
    "    \n",
    "    # Initialize the included solver\n",
    "    #    If you want to use your QP solver, you should write your own\n",
    "    #    method for this function\n",
    "    initialize_solver!(ctrl; kwargs...)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    update_QP!(ctrl::MPCController, x, time)\n",
    "\n",
    "Update the vectors in the QP problem for the current state `x` and time `time`.\n",
    "This should update `ctrl.q`, `ctrl.lb`, and `ctrl.ub`.\n",
    "\"\"\"\n",
    "function updateQP_constrained!(ctrl::MPCController, x, time)\n",
    "    # TODO: Implement this method\n",
    "\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constrained MPC controller\n",
    "Nd = (Nmpc-1)*(n+4)\n",
    "mpc2 = OSQPController(n, m, Nmpc, length(Xref), Nd)\n",
    "mpc2.Xref .= Xref\n",
    "mpc2.Uref .= Uref\n",
    "mpc2.times .= tref\n",
    "buildQP!(mpc2, A,B,Q,R,Qf, tol=1e-2, verbose=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isautograder || render(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmpc2,Umpc2,tmpc2 = simulate(model, x0, mpc2, tf=50)\n",
    "isautograder || visualize!(vis, model, tmpc2[end] / 10, Xmpc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results\n",
    "Let's check our plots again to see how we did! You should see that the solution now (mostly) satisfies the constraints. You should notice that it violates the roll angle limit slightly. Why do you think that is? Is there a way we could prevent that? In the next (and last) section, we'll explore the effects of changing the MPC horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isautograder || comparison_plot(model, (Xlqr,Ulqr,tlqr,\"LQR\"), (Xmpc1,Umpc1,tmpc1,\"MPC\"), (Xmpc2,Umpc2,tmpc2,\"MPC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"Q3d\" begin                             # POINTS = 12\n",
    "    Np = 50*(n+m)\n",
    "    Nd2 = 50*(n+4)\n",
    "    @test size(mpc2.A) == (Nd2,Np)               # POINTS = 2\n",
    "\n",
    "    @test norm(Xmpc2[end][4:6]) < 1e-2           # POINTS = 2 \n",
    "    @test norm(Xmpc2[end][1:3]) < 1e-2           # POINTS = 2\n",
    "    @test minimum([x[2] for x in Xmpc2]) < 0     # POINTS = 2\n",
    "    @test minimum([x[2] for x in Xmpc2]) > -0.1  # POINTS = 2\n",
    "    @test (maximum([x[7] for x in Xmpc2]) - RobotZoo.umax(model)[1]) < 1e-3     # POINTS = 1\n",
    "    @test maximum([abs(x[3]) for x in Xmpc2]) - deg2rad(model.max_roll) < 1e-1  # POINTS = 1\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (e): Changing the Horizon\n",
    "Let's see how our solution changes with the horizon. Note, there's nothing we're asking you to do here, just take minute to look at the plots and convince yourself of what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with a 1-step horizon\n",
    "Nmpc = 2\n",
    "\n",
    "# Constrained MPC\n",
    "mpc3 = OSQPController(n, m, Nmpc, length(Xref))\n",
    "mpc3.Xref .= Xref\n",
    "mpc3.Uref .= Uref\n",
    "mpc3.times .= tref\n",
    "buildQP!(mpc3, A,B,Q,R,Qf, tol=1e-2, verbose=false)\n",
    "Xmpc3,Umpc3,tmpc3 = simulate(model, Xref[1], mpc3, tf=50)\n",
    "\n",
    "# Constrained MPC\n",
    "Nd = (Nmpc-1)*(n+4)\n",
    "mpc4 = OSQPController(n, m, Nmpc, length(Xref), Nd)\n",
    "mpc4.Xref .= Xref\n",
    "mpc4.Uref .= Uref\n",
    "mpc4.times .= tref\n",
    "buildQP!(mpc4, A,B,Q,R,Qf, tol=1e-2, verbose=false)\n",
    "Xmpc4,Umpc4,tmpc4 = simulate(model, Xref[1], mpc4, tf=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isautograder || comparison_plot(model, (Xlqr,Ulqr,tlqr,\"LQR\"), (Xmpc3,Umpc3,tmpc3,\"MPC\"), (Xmpc4,Umpc4,tmpc4,\"MPC-Con\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with a bunch of horizons\n",
    "horizons = [21,31,41,51,61,71,81,91,101]\n",
    "\n",
    "Z = map(horizons) do Nmpc\n",
    "    # Constrained MPC\n",
    "    println(\"running with horizon = $Nmpc\")\n",
    "    Nd = (Nmpc-1)*(n+4)\n",
    "    mpc = OSQPController(n, m, Nmpc, length(Xref), Nd)\n",
    "    mpc.Xref .= Xref\n",
    "    mpc.Uref .= Uref\n",
    "    mpc.times .= tref\n",
    "    buildQP!(mpc, A,B,Q,R,Qf, tol=1e-2, verbose=false)\n",
    "    Xmpc,Umpc,tmpc = simulate(model, Xref[1], mpc, tf=50);\n",
    "    (Xmpc,Umpc,tmpc,\"N = \" * string(Nmpc))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isautograder || comparison_plot(model, Z...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit: Use your QP Solver\n",
    "You can earn some extra credit by using the AL QP solver you built in the previous homework. You'll get more extra credit if you modify your QP solver to handle the unique structure that exists in the MPC QP problem. Include an example of using your QP solver below, along with a description of your approach."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
